#!/usr/bin/env python3
"""
Load March Data from CSVs into Database

This script loads processed watch data CSVs (generated by process_watch_data.py)
into the march dashboard database.

Usage:
    # Load data from CSV files:
    python load_march_data.py --data-dir ./output --march-id 1

    # With custom database URL:
    python load_march_data.py --data-dir ./output --march-id 1 --db-url postgresql://user:pass@host:port/db

    # Dry run to see what would be loaded:
    python load_march_data.py --data-dir ./output --march-id 1 --dry-run

    # With custom participant ID mapping:
    python load_march_data.py --data-dir ./output --march-id 1 --mapping SM001:participant1,SM002:participant2
"""

import argparse
import os
import sys
from pathlib import Path

import numpy as np
import pandas as pd
from sqlalchemy import create_engine, text


def get_database_url(args):
    """Get database URL from arguments or environment"""
    if args.db_url:
        return args.db_url

    db_url = os.environ.get('DATABASE_URL')
    if db_url:
        print("Using DATABASE_URL from environment")
        return db_url

    default_url = "postgresql://postgres:password@localhost:5432/fitonduty_march"
    print(f"Using default database URL: {default_url}")
    return default_url


def create_db_engine(db_url):
    """Create database engine"""
    try:
        return create_engine(db_url)
    except Exception as e:
        print(f"Error creating database engine: {e}")
        sys.exit(1)


def load_csv_file(data_dir, filename):
    """Load a CSV file if it exists"""
    file_path = Path(data_dir) / filename
    if not file_path.exists():
        print(f"  ‚ö†Ô∏è  File not found: {filename}")
        return None

    try:
        df = pd.read_csv(file_path)
        print(f"  ‚úì Loaded {filename}: {len(df)} rows")
        return df
    except Exception as e:
        print(f"  ‚ùå Error loading {filename}: {e}")
        return None


def get_user_mapping(engine, custom_mapping=None):
    """
    Get mapping from participant IDs (like SM001) to database user IDs

    Args:
        engine: Database engine
        custom_mapping: Optional dict mapping participant_id -> username

    Returns:
        Dict mapping participant_id -> user_id
    """
    try:
        with engine.connect() as conn:
            # Get all participant users
            result = conn.execute(text("""
                SELECT id, username FROM users WHERE role = 'participant'
            """))
            users = {row[1]: row[0] for row in result}

        if not users:
            print("Error: No participant users found in database")
            return {}

        # If custom mapping provided, use it
        if custom_mapping:
            mapping = {}
            for participant_id, username in custom_mapping.items():
                if username in users:
                    mapping[participant_id] = users[username]
                    print(f"  ‚úì Mapped {participant_id} -> {username} (user_id={users[username]})")
                else:
                    print(f"  ‚ö†Ô∏è  Username '{username}' not found for participant {participant_id}")
            return mapping

        # Otherwise, try automatic mapping (participant_id == username)
        # This works if CSVs have user_id that matches database usernames
        print("\nAttempting automatic participant ID mapping...")
        print(f"Available users: {', '.join(users.keys())}")

        # Return a mapping where participant_id can be looked up as username
        return {username: user_id for username, user_id in users.items()}

    except Exception as e:
        print(f"Error getting user mapping: {e}")
        return {}


def verify_march_exists(engine, march_id):
    """Verify march event exists"""
    try:
        with engine.connect() as conn:
            result = conn.execute(text("""
                SELECT id, name, date, status FROM march_events WHERE id = :march_id
            """), {'march_id': march_id})
            row = result.fetchone()

            if not row:
                print(f"Error: March event with ID {march_id} not found")
                return False

            print(f"\nMarch Event: {row[1]} (ID={row[0]}, Date={row[2]}, Status={row[3]})")
            return True

    except Exception as e:
        print(f"Error verifying march: {e}")
        return False


def to_python_type(value):
    """
    Convert NumPy/pandas types to native Python types for database compatibility

    Args:
        value: Value to convert (may be NumPy type, pandas type, or Python type)

    Returns:
        Native Python type (int, float, str, None, etc.)
    """
    if pd.isna(value):
        return None
    if isinstance(value, (np.integer, np.int64, np.int32)):
        return int(value)
    if isinstance(value, (np.floating, np.float64, np.float32)):
        return float(value)
    if isinstance(value, (np.bool_, bool)):
        return bool(value)
    if isinstance(value, (np.str_, str)):
        return str(value)
    return value


def to_int(value):
    """Convert value to integer, handling None/NaN"""
    converted = to_python_type(value)
    return int(round(converted)) if converted is not None else None


def to_decimal(value, decimal_places=2, max_value=None):
    """
    Convert value to float with specified decimal places, handling None/NaN

    Args:
        value: Value to convert
        decimal_places: Number of decimal places to round to
        max_value: Optional maximum absolute value to cap at
    """
    converted = to_python_type(value)
    if converted is None:
        return None

    rounded = round(converted, decimal_places)

    # Cap at max_value if specified
    if max_value is not None:
        if rounded > max_value:
            return max_value
        if rounded < -max_value:
            return -max_value

    return rounded


def map_participant_ids(df, user_mapping):
    """
    Map participant IDs from CSV to database user IDs

    Args:
        df: DataFrame with 'user_id' column containing participant IDs
        user_mapping: Dict mapping participant_id -> database user_id

    Returns:
        DataFrame with 'user_id' mapped to database IDs, unmapped rows removed
    """
    if df is None or df.empty:
        return df

    original_count = len(df)

    # Map user_id using the mapping
    df['user_id'] = df['user_id'].map(user_mapping)

    # Remove rows where mapping failed
    unmapped_count = df['user_id'].isna().sum()
    if unmapped_count > 0:
        unmapped_ids = df[df['user_id'].isna()]['user_id'].unique()
        print(f"  ‚ö†Ô∏è  Could not map {unmapped_count} rows with IDs: {unmapped_ids}")
        df = df.dropna(subset=['user_id'])

    # Convert to integer
    df['user_id'] = df['user_id'].astype(int)

    print(f"  ‚úì Mapped {len(df)}/{original_count} rows to database user IDs")
    return df


def load_march_health_metrics(conn, df, march_id):
    """Load march health metrics data"""
    if df is None or df.empty:
        return 0

    print("\nLoading march health metrics...")
    loaded_count = 0

    for _, row in df.iterrows():
        try:
            # Convert all values to Python native types
            user_id = int(row['user_id'])
            finish_time = to_python_type(row.get('march_duration_minutes', 0))

            # First, ensure participant is registered for this march
            conn.execute(text("""
                INSERT INTO march_participants (march_id, user_id, completed, finish_time_minutes)
                VALUES (:march_id, :user_id, TRUE, :finish_time)
                ON CONFLICT (march_id, user_id)
                DO UPDATE SET completed = TRUE, finish_time_minutes = EXCLUDED.finish_time_minutes
            """), {
                'march_id': march_id,
                'user_id': user_id,
                'finish_time': finish_time
            })

            # Insert health metrics
            conn.execute(text("""
                INSERT INTO march_health_metrics (
                    march_id, user_id, avg_hr, max_hr, total_steps,
                    march_duration_minutes, estimated_distance_km, avg_pace_kmh,
                    effort_score, recovery_hr, avg_core_temp, data_completeness
                )
                VALUES (
                    :march_id, :user_id, :avg_hr, :max_hr, :total_steps,
                    :march_duration_minutes, :estimated_distance_km, :avg_pace_kmh,
                    :effort_score, :recovery_hr, :avg_core_temp, :data_completeness
                )
                ON CONFLICT (march_id, user_id)
                DO UPDATE SET
                    avg_hr = EXCLUDED.avg_hr,
                    max_hr = EXCLUDED.max_hr,
                    total_steps = EXCLUDED.total_steps,
                    march_duration_minutes = EXCLUDED.march_duration_minutes,
                    estimated_distance_km = EXCLUDED.estimated_distance_km,
                    avg_pace_kmh = EXCLUDED.avg_pace_kmh,
                    effort_score = EXCLUDED.effort_score,
                    recovery_hr = EXCLUDED.recovery_hr,
                    avg_core_temp = EXCLUDED.avg_core_temp,
                    data_completeness = EXCLUDED.data_completeness
            """), {
                'march_id': march_id,
                'user_id': user_id,
                'avg_hr': to_python_type(row.get('avg_hr')),
                'max_hr': to_python_type(row.get('max_hr')),
                'total_steps': to_python_type(row.get('total_steps')),
                'march_duration_minutes': to_python_type(row.get('march_duration_minutes')),
                'estimated_distance_km': to_python_type(row.get('estimated_distance_km')),
                'avg_pace_kmh': to_python_type(row.get('avg_pace_kmh')),
                'effort_score': to_python_type(row.get('effort_score')),
                'recovery_hr': to_python_type(row.get('recovery_hr')),
                'avg_core_temp': to_python_type(row.get('avg_core_temp')),
                'data_completeness': to_python_type(row.get('data_completeness', 1.0))
            })

            loaded_count += 1

        except Exception as e:
            print(f"  ‚ùå Error loading metrics for user {row['user_id']}: {e}")

    print(f"  ‚úì Loaded {loaded_count} health metrics records")
    return loaded_count


def load_march_hr_zones(conn, df, march_id):
    """Load march HR zones data"""
    if df is None or df.empty:
        return 0

    print("\nLoading march HR zones...")
    loaded_count = 0

    for _, row in df.iterrows():
        try:
            # Convert user_id to Python int
            user_id = int(row['user_id'])

            # Get the health metric ID for this participant
            result = conn.execute(text("""
                SELECT id FROM march_health_metrics
                WHERE march_id = :march_id AND user_id = :user_id
            """), {
                'march_id': march_id,
                'user_id': user_id
            })

            metric_row = result.fetchone()
            if not metric_row:
                print(f"  ‚ö†Ô∏è  No health metric found for user {user_id}, skipping HR zones")
                continue

            metric_id = metric_row[0]

            # Insert HR zones
            conn.execute(text("""
                INSERT INTO march_hr_zones (
                    march_health_metric_id, very_light_percent, light_percent,
                    moderate_percent, intense_percent, beast_mode_percent
                )
                VALUES (
                    :metric_id, :very_light_percent, :light_percent,
                    :moderate_percent, :intense_percent, :beast_mode_percent
                )
                ON CONFLICT (march_health_metric_id)
                DO UPDATE SET
                    very_light_percent = EXCLUDED.very_light_percent,
                    light_percent = EXCLUDED.light_percent,
                    moderate_percent = EXCLUDED.moderate_percent,
                    intense_percent = EXCLUDED.intense_percent,
                    beast_mode_percent = EXCLUDED.beast_mode_percent
            """), {
                'metric_id': metric_id,
                'very_light_percent': to_python_type(row.get('very_light_percent', 0)),
                'light_percent': to_python_type(row.get('light_percent', 0)),
                'moderate_percent': to_python_type(row.get('moderate_percent', 0)),
                'intense_percent': to_python_type(row.get('intense_percent', 0)),
                'beast_mode_percent': to_python_type(row.get('beast_mode_percent', 0))
            })

            loaded_count += 1

        except Exception as e:
            print(f"  ‚ùå Error loading HR zones for user {row['user_id']}: {e}")

    print(f"  ‚úì Loaded {loaded_count} HR zones records")
    return loaded_count


def load_march_timeseries_data(conn, df, march_id):
    """Load march timeseries data"""
    if df is None or df.empty:
        return 0

    print("\nLoading march timeseries data...")

    # Delete existing timeseries data for this march to avoid conflicts
    print("  Deleting existing timeseries data for this march...")
    conn.execute(text("""
        DELETE FROM march_timeseries_data WHERE march_id = :march_id
    """), {'march_id': march_id})

    loaded_count = 0
    batch_size = 1000

    # Prepare data for batch insert
    records = []
    for _, row in df.iterrows():
        # Convert values to match database schema types
        # timestamp_minutes: INTEGER
        timestamp_val = to_python_type(row.get('timestamp_minutes', 0))
        timestamp_minutes = int(round(timestamp_val)) if timestamp_val is not None else 0

        records.append({
            'march_id': march_id,
            'user_id': int(row['user_id']),
            'timestamp_minutes': timestamp_minutes,
            'heart_rate': to_int(row.get('heart_rate')),  # INTEGER
            'step_rate': to_int(row.get('step_rate')),  # INTEGER
            'estimated_speed_kmh': to_decimal(row.get('speed_kmh') or row.get('estimated_speed_kmh'), 2, max_value=99.99),  # NUMERIC(4,2) - max 99.99
            'cumulative_steps': to_int(row.get('steps') or row.get('cumulative_steps')),  # INTEGER
            'cumulative_distance_km': to_decimal(row.get('cumulative_distance_km'), 2, max_value=999.99)  # NUMERIC(5,2) - max 999.99
        })

        # Insert in batches
        if len(records) >= batch_size:
            conn.execute(text("""
                INSERT INTO march_timeseries_data (
                    march_id, user_id, timestamp_minutes, heart_rate, step_rate,
                    estimated_speed_kmh, cumulative_steps, cumulative_distance_km
                )
                VALUES (
                    :march_id, :user_id, :timestamp_minutes, :heart_rate, :step_rate,
                    :estimated_speed_kmh, :cumulative_steps, :cumulative_distance_km
                )
                ON CONFLICT (march_id, user_id, timestamp_minutes) DO UPDATE SET
                    heart_rate = COALESCE(EXCLUDED.heart_rate, march_timeseries_data.heart_rate),
                    step_rate = COALESCE(EXCLUDED.step_rate, march_timeseries_data.step_rate),
                    estimated_speed_kmh = COALESCE(EXCLUDED.estimated_speed_kmh, march_timeseries_data.estimated_speed_kmh),
                    cumulative_steps = COALESCE(EXCLUDED.cumulative_steps, march_timeseries_data.cumulative_steps),
                    cumulative_distance_km = COALESCE(EXCLUDED.cumulative_distance_km, march_timeseries_data.cumulative_distance_km)
            """), records)
            loaded_count += len(records)
            print(f"  ... loaded {loaded_count} records")
            records = []

    # Insert remaining records
    if records:
        conn.execute(text("""
            INSERT INTO march_timeseries_data (
                march_id, user_id, timestamp_minutes, heart_rate, step_rate,
                estimated_speed_kmh, cumulative_steps, cumulative_distance_km
            )
            VALUES (
                :march_id, :user_id, :timestamp_minutes, :heart_rate, :step_rate,
                :estimated_speed_kmh, :cumulative_steps, :cumulative_distance_km
            )
            ON CONFLICT (march_id, user_id, timestamp_minutes) DO UPDATE SET
                heart_rate = COALESCE(EXCLUDED.heart_rate, march_timeseries_data.heart_rate),
                step_rate = COALESCE(EXCLUDED.step_rate, march_timeseries_data.step_rate),
                estimated_speed_kmh = COALESCE(EXCLUDED.estimated_speed_kmh, march_timeseries_data.estimated_speed_kmh),
                cumulative_steps = COALESCE(EXCLUDED.cumulative_steps, march_timeseries_data.cumulative_steps),
                cumulative_distance_km = COALESCE(EXCLUDED.cumulative_distance_km, march_timeseries_data.cumulative_distance_km)
        """), records)
        loaded_count += len(records)

    print(f"  ‚úì Loaded {loaded_count} timeseries records")
    return loaded_count


def load_march_gps_positions(conn, df, march_id):
    """Load march GPS positions data"""
    if df is None or df.empty:
        return 0

    print("\nLoading march GPS positions...")

    # Delete existing GPS data for this march to avoid conflicts
    print("  Deleting existing GPS data for this march...")
    conn.execute(text("""
        DELETE FROM march_gps_positions WHERE march_id = :march_id
    """), {'march_id': march_id})

    loaded_count = 0
    batch_size = 1000

    # Prepare data for batch insert
    records = []
    for _, row in df.iterrows():
        records.append({
            'march_id': march_id,
            'user_id': int(row['user_id']),
            'timestamp_minutes': to_python_type(row.get('timestamp_minutes', 0)),
            'latitude': to_python_type(row.get('latitude')),
            'longitude': to_python_type(row.get('longitude')),
            'elevation': to_python_type(row.get('elevation')),
            'speed_kmh': to_python_type(row.get('speed_kmh')),
            'bearing': to_python_type(row.get('bearing'))
        })

        # Insert in batches
        if len(records) >= batch_size:
            conn.execute(text("""
                INSERT INTO march_gps_positions (
                    march_id, user_id, timestamp_minutes, latitude, longitude,
                    elevation, speed_kmh, bearing
                )
                VALUES (
                    :march_id, :user_id, :timestamp_minutes, :latitude, :longitude,
                    :elevation, :speed_kmh, :bearing
                )
            """), records)
            loaded_count += len(records)
            print(f"  ... loaded {loaded_count} records")
            records = []

    # Insert remaining records
    if records:
        conn.execute(text("""
            INSERT INTO march_gps_positions (
                march_id, user_id, timestamp_minutes, latitude, longitude,
                elevation, speed_kmh, bearing
            )
            VALUES (
                :march_id, :user_id, :timestamp_minutes, :latitude, :longitude,
                :elevation, :speed_kmh, :bearing
            )
        """), records)
        loaded_count += len(records)

    print(f"  ‚úì Loaded {loaded_count} GPS position records")
    return loaded_count


def load_march_core_temp_data(conn, df, march_id):
    """Load march core temperature timeseries data"""
    if df is None or df.empty:
        return 0

    print("\nLoading march core temperature data...")

    loaded_count = 0
    batch_size = 1000

    # Prepare data for batch insert/update
    records = []
    for _, row in df.iterrows():
        timestamp_val = to_python_type(row.get('timestamp_minutes', 0))
        timestamp_minutes = int(round(timestamp_val)) if timestamp_val is not None else 0

        records.append({
            'march_id': march_id,
            'user_id': int(row['user_id']),
            'timestamp_minutes': timestamp_minutes,
            'core_temp': to_decimal(row.get('core_temp'), 2, max_value=45.0)
        })

        # Insert in batches
        if len(records) >= batch_size:
            conn.execute(text("""
                INSERT INTO march_timeseries_data (
                    march_id, user_id, timestamp_minutes, core_temp
                )
                VALUES (
                    :march_id, :user_id, :timestamp_minutes, :core_temp
                )
                ON CONFLICT (march_id, user_id, timestamp_minutes)
                DO UPDATE SET core_temp = EXCLUDED.core_temp
            """), records)
            loaded_count += len(records)
            print(f"  ... loaded {loaded_count} temperature records")
            records = []

    # Insert remaining records
    if records:
        conn.execute(text("""
            INSERT INTO march_timeseries_data (
                march_id, user_id, timestamp_minutes, core_temp
            )
            VALUES (
                :march_id, :user_id, :timestamp_minutes, :core_temp
            )
            ON CONFLICT (march_id, user_id, timestamp_minutes)
            DO UPDATE SET core_temp = EXCLUDED.core_temp
        """), records)
        loaded_count += len(records)

    print(f"  ‚úì Loaded {loaded_count} temperature records")
    return loaded_count


def parse_custom_mapping(mapping_str):
    """
    Parse custom mapping string like "SM001:participant1,SM002:participant2"

    Returns:
        Dict mapping participant_id -> username
    """
    if not mapping_str:
        return None

    mapping = {}
    for pair in mapping_str.split(','):
        if ':' in pair:
            participant_id, username = pair.split(':', 1)
            mapping[participant_id.strip()] = username.strip()

    return mapping if mapping else None


def main():
    parser = argparse.ArgumentParser(
        description='Load processed watch data CSVs into march dashboard database',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        '--data-dir',
        required=True,
        help='Directory containing CSV files (output from process_watch_data.py)'
    )

    parser.add_argument(
        '--march-id',
        type=int,
        required=True,
        help='March event ID to load data for'
    )

    parser.add_argument(
        '--db-url',
        help='Database connection URL (default: DATABASE_URL env var or local default)'
    )

    parser.add_argument(
        '--mapping',
        help='Custom participant ID mapping: "ID1:username1,ID2:username2"'
    )

    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Show what would be loaded without making changes'
    )

    args = parser.parse_args()

    print("=== Load March Data from CSVs ===\n")

    # Get database URL and create engine
    db_url = get_database_url(args)
    engine = create_db_engine(db_url)

    # Test connection
    try:
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
        print("‚úì Database connection successful\n")
    except Exception as e:
        print(f"‚ùå Database connection failed: {e}")
        sys.exit(1)

    # Verify march exists
    if not verify_march_exists(engine, args.march_id):
        sys.exit(1)

    # Parse custom mapping if provided
    custom_mapping = parse_custom_mapping(args.mapping)
    if custom_mapping:
        print(f"\nUsing custom participant mapping: {custom_mapping}")

    # Get user mapping
    user_mapping = get_user_mapping(engine, custom_mapping)
    if not user_mapping:
        print("Error: Could not create user mapping")
        sys.exit(1)

    # Load CSV files
    print("\nLoading CSV files...")
    data_dir = Path(args.data_dir)

    metrics_df = load_csv_file(data_dir, 'march_health_metrics.csv')
    hr_zones_df = load_csv_file(data_dir, 'march_hr_zones.csv')
    timeseries_df = load_csv_file(data_dir, 'march_timeseries_data.csv')
    gps_df = load_csv_file(data_dir, 'march_gps_positions.csv')
    temp_df = load_csv_file(data_dir, 'march_temp_data.csv')

    if all(df is None for df in [metrics_df, hr_zones_df, timeseries_df, gps_df, temp_df]):
        print("\n‚ùå No CSV files found or all files are empty")
        sys.exit(1)

    # Map participant IDs to database user IDs
    print("\nMapping participant IDs to database user IDs...")
    if metrics_df is not None:
        metrics_df = map_participant_ids(metrics_df, user_mapping)
    if hr_zones_df is not None:
        hr_zones_df = map_participant_ids(hr_zones_df, user_mapping)
    if timeseries_df is not None:
        timeseries_df = map_participant_ids(timeseries_df, user_mapping)
    if gps_df is not None:
        gps_df = map_participant_ids(gps_df, user_mapping)
    if temp_df is not None:
        temp_df = map_participant_ids(temp_df, user_mapping)

    if args.dry_run:
        print("\nüîç DRY RUN - No changes will be made")
        print(f"\nWould load:")
        if metrics_df is not None:
            print(f"  - {len(metrics_df)} health metrics records")
        if hr_zones_df is not None:
            print(f"  - {len(hr_zones_df)} HR zones records")
        if timeseries_df is not None:
            print(f"  - {len(timeseries_df)} timeseries records")
        if gps_df is not None:
            print(f"  - {len(gps_df)} GPS position records")
        if temp_df is not None:
            print(f"  - {len(temp_df)} core temperature records")
        sys.exit(0)

    # Confirm before proceeding
    response = input(f"\nProceed with loading data for march ID {args.march_id}? (y/N): ")
    if response.lower() != 'y':
        print("Cancelled")
        sys.exit(0)

    # Load data into database
    try:
        with engine.begin() as conn:
            # Load in order: metrics -> hr_zones -> timeseries -> gps
            total_loaded = 0

            if metrics_df is not None:
                total_loaded += load_march_health_metrics(conn, metrics_df, args.march_id)

            if hr_zones_df is not None:
                total_loaded += load_march_hr_zones(conn, hr_zones_df, args.march_id)

            if timeseries_df is not None:
                total_loaded += load_march_timeseries_data(conn, timeseries_df, args.march_id)

            if gps_df is not None:
                total_loaded += load_march_gps_positions(conn, gps_df, args.march_id)

            if temp_df is not None:
                total_loaded += load_march_core_temp_data(conn, temp_df, args.march_id)

            print(f"\n‚úÖ Successfully loaded {total_loaded} total records!")
            print(f"\nMarch {args.march_id} data has been updated.")
            print("You may want to update the march status to 'published' to make it visible.")

    except Exception as e:
        print(f"\n‚ùå Error loading data: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()